# Back-end User Data API (Clean Architecture)

A high-performance, robust Express.js API designed to serve user data
with advanced caching, rate limiting, and asynchronous processing. This
project strictly adheres to **Clean Architecture (Onion/Hexagonal
Architecture)** principles, ensuring complete decoupling of business
logic from infrastructure.

---

## üèó Architectural Design

The solution follows the **Dependency Rule**, where source code
dependencies only point inwards.
The core business logic knows nothing about the database, the web
framework, or external services.

---

## üìö Layer Breakdown

### **1. Domain Layer (`src/domain`)**

- **Role:** Enterprise business rules
- **Contents:** Entities (`User`, `CacheStats`), Repository Interfaces
  (Ports)
- **Dependencies:** None --- pure TypeScript

### **2. Application Layer (`src/application`)**

- **Role:** Application business logic (Use Cases)
- **Contents:** `GetUserUseCase`, `CreateUserUseCase`
- **Logic Flow:**
  - Check Cache
  - If cache miss ‚Üí Queue DB Fetch
  - Update Cache
  - Return response

### **3. Interface Adapters Layer (`src/interfaces`)**

- **Role:** Data conversion between use cases and external I/O
- **Contents:** `UserController`

### **4. Infrastructure Layer (`src/infrastructure`)**

- **Role:** Frameworks and drivers
- **Contents:**
  - **Repositories:** `InMemoryLRUCacheRepository`,
    `MockUserRepository`
  - **Services:** `PrometheusMonitoringService`
  - **Web:** Express server, Rate Limit Middleware

---

## üöÄ Key Technical Features

### **1. Advanced Caching (LRU Strategy)**

- Custom in-memory **Least Recently Used (LRU)** cache
- **TTL:** 60 seconds
- **Max Capacity:** 100 items
- **Cleanup:** Background interval every 10 seconds
- **File:**
  `src/infrastructure/repositories/InMemoryLRUCacheRepository.ts`

---

### **2. Concurrency & Request Coalescing**

- Avoids duplicate DB fetches for simultaneous requests
- If a request for the same ID is already in-flight, other requests
  **subscribe** to the same Promise
- **File:** `src/infrastructure/repositories/MockUserRepository.ts`

---

### **3. Asynchronous Processing Queue**

- Simple in-memory queue throttling DB access
- Prevents system overload with controlled concurrency

---

### **4. Sophisticated Rate Limiting**

Algorithm: **Token Bucket / Sliding Window**

Rules: - **10 req/min** standard limit

- **5 req / 10 sec** burst limit

Response: - Returns **429 Too Many Requests** with specific messages

---

### **5. Monitoring (Bonus)**

Using **prom-client** for Prometheus metrics.

Tracked Metrics: - `http_request_duration_ms` - `cache_hits_total` -
`cache_misses_total`

---

## üìÇ Project Structure

    backend-assignment/
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ domain/                  # Entities & Interface Definitions
    ‚îÇ   ‚îú‚îÄ‚îÄ application/             # Use Case Orchestration
    ‚îÇ   ‚îú‚îÄ‚îÄ interfaces/              # Controllers
    ‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/          # Database, Cache, Web Framework impl
    ‚îÇ   ‚îî‚îÄ‚îÄ main.ts                  # Dependency Injection Root
    ‚îú‚îÄ‚îÄ package.json
    ‚îî‚îÄ‚îÄ tsconfig.json

---

## üõ† Setup & Installation

### **Prerequisites**

- Node.js (v14+)
- npm

### **Installation**

```bash
git clone https://github.com/QaziDanish/backend-assignment.git
cd backend-assignment
npm install
```

### **Running the Application**

Development:

```bash
npm run dev
```

Production:

```bash
npm run build
npm start
```

Server runs on **port 3000**.

---

## üß™ Testing the API

### **1. Fetch User (Caching & Concurrency)**

**GET** `http://localhost:3000/users/1`

Expected: - First request: \~200ms (**Cache Miss**)

- Second request: \~1--5ms (**Cache Hit**)
- 10 parallel requests ‚Üí only **one** DB operation

---

### **2. Rate Limiting**

Send \>5 requests in 10 seconds.

Expected: - **429 Too Many Requests --- "Burst limit exceeded"**

---

### **3. Create User (Write-Through Cache)**

**POST** `http://localhost:3000/users`

Body:

```json
{ "name": "New User", "email": "new@test.com" }
```

Result: - User created & immediately stored in cache

---

### **4. Monitoring & Stats**

- **Cache Stats:** `GET /cache-status`
- **Prometheus Metrics:** `GET /metrics`

### **5. Administrative**

- **Clear Cache:** `DELETE /cache`

---

## ‚öñÔ∏è Trade-offs & Decisions

### **In-Memory Cache vs Redis**

- In-memory used to demonstrate algorithmic understanding\
- Clean Architecture allows easy swap to Redis later

### **Manual Queue vs BullMQ**

- Native JS queue used for simplicity\
- Production systems recommended to use **BullMQ** or similar

---
